# <center>INSTA与libfewshot读取参数机制
## <center>INSTA读取参数机制

INSTA通过`get_command_line_parser()`读取参数，该函数会查找所有可能的参数是否在命令行中指定，若指定，则使用指定的值，不然则使用默认值。

以下是`get_command_line_parser()`中出现的所有参数：

- 通用参数

  - `max_epoch`：训练的最大迭代次数。模型将会训练 `max_epoch` 次。
  - `episodes_per_epoch`：每个 epoch 中的 episode 数量。一个 episode 通常是一个任务，如 5-way 1-shot 任务。
  - `num_eval_episodes`：评估时使用的 episode 数量。用于评估模型在验证集或测试集上的性能。

- 模型和优化器参数

  - `model_class`：模型的类别。可以选择不同的模型结构，例如 `INSTA_ProtoNet` 或 `ProtoNet`。
  - `use_euclidean`：是否使用欧几里得距离。如果为 True，则在度量空间中使用欧几里得距离。
  - `use_AdamW`：是否使用 AdamW 优化器。AdamW 是 Adam 优化器的一个变体，具有权重衰减（weight decay）功能。

- Backbone 参数

  - `backbone_class`：backbone 的类别。可以选择不同的 ResNet 结构，例如 `Res12` 或 `Res18`。
  - `dataset`：使用的数据集名称。例如 `MiniImageNet`, `TieredImageNet`, `CUB`, `FC100`。

- Few-shot 学习任务参数

  - `way`：训练时的类别数量（N-way）。
  - `eval_way`：评估时的类别数量（N-way）。
  - `shot`：每个类别的样本数量（K-shot）。
  - `eval_shot`：评估时每个类别的样本数量（K-shot）。
  - `query`：每个类别中的查询样本数量。
  - `eval_query`：评估时每个类别中的查询样本数量。

- 平衡参数

  - `balance_1`：平衡参数，可能用于平衡不同损失项或正则化项。
  - `balance_2`：另一个平衡参数，功能类似于 `balance_1`。

- 温度参数

  - `temperature`：温度参数，可能用于缩放 logits，以调整软标签（soft label）的平滑度。
  - `temperature2`：另一个温度参数，具体用途需要在代码中进一步查看。

- 优化参数

  - `orig_imsize`：原始图像大小。用于决定是否缓存图像或调整图像大小。
  - `lr`：学习率。
  - `lr_mul`：学习率乘数。可能用于调整特定层的学习率。
  - `lr_scheduler`：学习率调度器的类型，例如 `step`, `multistep`, `cosine`。
  - `step_size`：学习率调度器的步长。
  - `gamma`：学习率调度器的衰减系数。
  - `fix_BN`：是否固定 Batch Normalization 层的均值和方差。
  - `augment`：是否使用数据增强。
  - `baseline`：基线模型的类型。
  - `multi_gpu`：是否使用多 GPU 训练。
  - `gpu`：指定使用的 GPU 设备编号。
  - `init_weights`：预训练权重的路径。
  - `emb_adap`：是否使用嵌入自适应。
  - `testing`：是否处于测试模式。

- 其他参数

  - `mom`：动量，用于优化器。
  - `weight_decay`：权重衰减系数，用于 L2 正则化。
  - `num_workers`：用于数据加载的工作线程数。
  - `log_interval`：日志记录的间隔。
  - `eval_interval`：评估的间隔。
  - `save_dir`：检查点保存路径。

参数以`args`形式传递：
```python
parser = get_command_line_parser()
args = postprocess_args(parser.parse_args())

trainer = FSLTrainer(args)
```
类似于一个`dictory`变量，在接下来的代码中均使用`args`传递设置参数。

## <center>libfewshot读取参数机制

libfewshot中参数指定的优先级如下(优先级高的指定会覆盖优先级低的指定)：`console_params > run_*.py dict > user defined yaml (/LibFewShot/config/*.yaml) > default.yaml (/LibFewShot/core/config/default.yaml)`

libfewshot中参数指定相对自由，其中关于`backbone`和`classifier`中参数的命名没有强制要求，只要在yaml文件中指定的名称与对应结构中的名称相对应，就可以识别并传递，但是对于其他部分的参数指定有固定的命名，不过其利用的机制与INSTA中类似：
```python
args = parser.parse_args()
# Remove key-None pairs
return {k: v for k, v in vars(args).items() if v is not None}
```
多了一个去除未指定参数的步骤。

固定命名的参数：

- Few-shot 学习任务参数

  - `-w, --way_num`：N-way 中的类别数量。每个 episode 中包含的类别数目。
  - `-s, --shot_num`：K-shot 中的样本数量。每个类别的支持集样本数目。
  - `-q, --query_num`：查询集中的样本数量。每个类别的查询集样本数目。
  - `-bs, --batch_size`：批次大小。在训练过程中每个批次中包含的样本数量。
  - `-es, --episode_size`：每个 episode 包含的任务数量。

- 数据集参数

  - `-data, --data_root`：数据集的路径。指向数据集所在的目录。
  - `-log_name, --log_name`：日志目录名称。指定日志文件保存的目录名称。
  - `-image_size`：图像大小。输入图像的尺寸。
  - `-aug, --augment`：是否使用数据增强。布尔值，表示是否对数据进行增强。
  - `-aug_times, --augment_times`：数据增强的次数。指定支持集的样本进行数据增强的次数。
  - `-aug_times_query, --augment_times_query`：查询集的样本进行数据增强的次数。

- 训练和测试参数

  - `-train_episode`：训练时的 episode 数量。在训练过程中每个 epoch 中的任务数量。
  - `-test_episode`：测试时的 episode 数量。在测试过程中每个 epoch 中的任务数量。
  - `-epochs`：训练的 epoch 数量。模型将会训练 `epochs` 个周期。
  - `-result, --result_root`：结果保存路径。指定保存训练结果的目录。
  - `-save_interval`：检查点保存间隔。每隔多少个 epoch 保存一次模型。

- 日志和设备参数

  - `-log_level`：日志级别。可以选择 `debug`, `info`, `warning`, `error`, `critical`。
  - `-log_interval`：日志记录的间隔。每隔多少个 batch 记录一次日志。
  - `-gpus, --device_ids`：设备 ID。指定用于训练的 GPU 设备编号。
  - `-n_gpu`：GPU 数量。用于指定训练时使用的 GPU 数量。
  - `-seed`：随机种子。用于设置随机数生成器的种子，以保证结果的可重复性。
  - `-deterministic`：是否使用确定性算法。布尔值，表示是否使用确定性算法以确保可重复性。
  - `-tag, --tag`：实验标签。用于标记实验，以便于记录和区分不同的实验。

也就是我们只需要找出INSTA中的所有需要指定的参数以及其适合的值，对于libfewshot中有固定命名的使用固定的命名，其他的在无冲突的情况下直接使用INSTA中的命名就可以了，^_^

## <center>INSTA与libfewshot间命名对照

见上两部分。

## <center>libfewshot中一些默认的参数设置

```python
# If test_* is not defined, replace with *_num.
        if config_dict["test_way"] is None:
            config_dict["test_way"] = config_dict["way_num"]
        if config_dict["test_shot"] is None:
            config_dict["test_shot"] = config_dict["shot_num"]
        if config_dict["test_query"] is None:
            config_dict["test_query"] = config_dict["query_num"]
        if config_dict["port"] is None:
            port = random.randint(25000, 55000)
            while self.is_port_in_use("127.0.0.1", port):
                old_port = port
                port = str(int(port) + 1)
                print(
                    "Warning: Port {} is already in use, switch to port {}".format(
                        old_port, port
                    )
                )
            config_dict["port"] = port

        # Modify or add some configs
        config_dict["resume"] = self.is_resume
        if self.is_resume:
            config_dict["resume_path"] = self.config_file[: -1 * len("/config.yaml")]
        config_dict["tb_scale"] = (
            float(config_dict["train_episode"]) / config_dict["test_episode"]
        )
```

## <center>总结

1. 两个项目处理参数的方法类似：`argparse.ArgumentParser()`
2. libfewshot中对于`backbone`和`classifier`中的参数没有强制的命名要求，只要能与实际结构中命名相对应即可
3. libfewshot中对于2中不包括部分有命名规范，需注意与INSTA中具体哪个参数相对应

